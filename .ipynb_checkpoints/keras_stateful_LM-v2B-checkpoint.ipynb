{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derek/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/derek/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "cardtext = [list(x) for x in list(np.load('data/card_texts.npy'))]\n",
    "c2i = np.load('data/c2i.npy').item()\n",
    "i2c = np.load('data/i2c.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test - randomize!\n",
    "np.random.seed = 1337\n",
    "indices = list(np.random.permutation(len(cardtext)))\n",
    "cardtext = [cardtext[i] for i in indices]\n",
    "# cardtext = cardtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "DROP_RATE = 0.25 # dropout\n",
    "EMBEDDING_SIZE = 200 # embedding size\n",
    "HIDDEN_SIZE = 200 # lstm feature vector\n",
    "HIDDEN_LAYERS = 2 # number of layers\n",
    "START_EPOCH = 0\n",
    "VOCAB_SIZE = len(c2i.keys()) # number of characters\n",
    "\n",
    "WINDOW_SIZE = 50 # context length\n",
    "CARDS_PER_BATCH = 5\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "OUT_INCREMENT = 100 # printout after n batches - and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardGenerator(cardtext, windowsize, cards_per_batch, c2i=c2i, debug=False):\n",
    "    \n",
    "    i = 0\n",
    "    indices = list(np.random.permutation(len(cardtext)))\n",
    "    idx = indices[i]\n",
    "    \n",
    "    def nextcard(cardtext, idx, debug=debug):\n",
    "        if debug:\n",
    "            card_idx = cardtext[idx]\n",
    "        else:\n",
    "            card_idx = [c2i[c] for c in cardtext[idx]]\n",
    "        \n",
    "        return list(card_idx)\n",
    "    \n",
    "    # pregenerate warmup sequence\n",
    "    if debug:\n",
    "        sequence = list(cardtext[idx][-(windowsize):])\n",
    "    else:\n",
    "        sequence = list([c2i[c] for c in cardtext[idx][-(windowsize):]])\n",
    "    i += 1\n",
    "    idx = indices[i]\n",
    "    for j in range(cards_per_batch):\n",
    "        sequence += nextcard(cardtext, idx)\n",
    "        i += 1\n",
    "        idx = indices[i]\n",
    "\n",
    "    # create matrix\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    # main iterator\n",
    "    while True:\n",
    "        \n",
    "        # generate batch (of cards_per_batch cards)\n",
    "        while len(sequence) > windowsize:\n",
    "            x.append(np.array(sequence[:windowsize]))\n",
    "            y.append(sequence[windowsize])\n",
    "            sequence.pop(0)\n",
    "        \n",
    "        # generate batch_size worth of window-shifted data\n",
    "        # reshape for sparse_categorical_crossentropy\n",
    "        sequence = []\n",
    "        y = np.array(y)\n",
    "        y = y[:, np.newaxis]\n",
    "        # yield and reset\n",
    "        yield(np.asarray(x), y)\n",
    "        x, y = [], []\n",
    "        \n",
    "        # check for too long, reset\n",
    "        if len(indices[i:]) < cards_per_batch+1:\n",
    "            indices = np.random.permutation(len(cardtext))\n",
    "            i = 0\n",
    "            idx = indices[i]\n",
    "        else:\n",
    "            i += 1\n",
    "            idx = indices[i]\n",
    "            \n",
    "        # pregenerate warmup sequence\n",
    "        if debug:\n",
    "            sequence = list(cardtext[idx][-(windowsize):])\n",
    "        else:\n",
    "            sequence = list([c2i[c] for c in cardtext[idx][-(windowsize):]])\n",
    "        i += 1\n",
    "        idx = indices[i]\n",
    "        for j in range(cards_per_batch):\n",
    "            sequence += nextcard(cardtext, idx)\n",
    "            i += 1\n",
    "            idx = indices[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "getbatch = cardGenerator(cardtext, WINDOW_SIZE, CARDS_PER_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBEDDING_SIZE, \n",
    "                    batch_input_shape=(1, WINDOW_SIZE, )))\n",
    "model.add(Dropout(DROP_RATE))\n",
    "for _ in range(HIDDEN_LAYERS-1):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(HIDDEN_SIZE, stateful=True))\n",
    "model.add(Dense(VOCAB_SIZE, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 'Ⓔ'\n",
    "\n",
    "def predict(startchars='none', temperature=1.0, maxlen=300):\n",
    "    \n",
    "    seq_out = []\n",
    "    \n",
    "    if temperature=='random':\n",
    "        tmp = np.random.random()\n",
    "    else:\n",
    "        tmp = temperature\n",
    "    \n",
    "    # starting sequence\n",
    "    if startchars=='none':\n",
    "        seq_in = [c2i['Ⓔ'] for i in range(WINDOW_SIZE)]\n",
    "    \n",
    "    elif startchars=='random':\n",
    "        seq_in = []\n",
    "        alpha = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',\n",
    "                 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
    "                 'w', 'x', 'y', 'z']\n",
    "        alpha = [a for a in alpha if a in c2i.keys()]\n",
    "        while len(seq_in) < WINDOW_SIZE-1:\n",
    "            rnd = np.random.randint(0, len(alpha))\n",
    "            seq_in += [c2i[alpha[rnd]]]\n",
    "        seq_in += [c2i['Ⓔ']]\n",
    "    \n",
    "    else:\n",
    "        s = list(startchars)\n",
    "        s = s[:WINDOW_SIZE]\n",
    "        seq_out =  [c2i[c] for c in s]\n",
    "        while len(s) < WINDOW_SIZE:\n",
    "            s.insert(0, 'Ⓔ')\n",
    "        seq_in = [c2i[c] for c in s]\n",
    "        \n",
    "    # softmax temperature\n",
    "    # scaling factor of logits = logits/temperature\n",
    "    # high temp = more confident = more diverse, more mistakes\n",
    "    # low temp: more conservative\n",
    "    # https://stackoverflow.com/questions/37246030/how-to-change-the-temperature-of-a-softmax-output-in-keras/37254117#37254117\n",
    "    def sample(a, temperature=tmp):\n",
    "        a = np.array(a)**(1/temperature)\n",
    "        p_sum = a.sum()\n",
    "        sample_temp = a/p_sum \n",
    "\n",
    "        # stupid fix for > 1 error\n",
    "        while sum(sample_temp) > 1:\n",
    "            sample_temp[0] -= 0.0001\n",
    "\n",
    "        return np.argmax(np.random.multinomial(1, sample_temp, 1))\n",
    "\n",
    "    for i in range(maxlen):\n",
    "\n",
    "        # predict next char\n",
    "        pred_out = model.predict(np.array(seq_in).reshape((1, WINDOW_SIZE)))\n",
    "        # get index of highest pred\n",
    "        idx = sample(pred_out[0])\n",
    "        # save index for decoding\n",
    "        seq_out.append(idx)\n",
    "        # add index to input sequence\n",
    "        seq_in.append(int(idx))\n",
    "        # remove earliest\n",
    "        seq_in.pop(0)\n",
    "\n",
    "    # decode final sequence\n",
    "    card_char = ''.join([i2c[int(i)] for i in seq_out])\n",
    "    card_char = card_char.replace('·', '|')\n",
    "    card_char = card_char.replace('Ⓔ', 'Ⓔ\\n|')\n",
    "    card_text = card_char.split('|')\n",
    "\n",
    "    for f in card_text:\n",
    "        print(f)\n",
    "        \n",
    "    return card_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model.load_weights('model/temp-modelweights-epoch26-batch957.h5')\n",
    "# START_EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5869 [1:37:25<93:40:38, 58.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 card #: 100 of 29347 <keras.callbacks.History object at 0x7f38d8693eb8>\n",
      "ng of the battlefield of turn.Ⓔ\n",
      "\n",
      "ceching a creature pay put the battlefield then creature the battlefield then creature the battlefield target and target creature library.Ⓔ\n",
      "\n",
      "cuman serresting ond target land onto the battlefield your mana controller then creature that card and intile ond target creature \n",
      "shan\n",
      "③Ⓖ\n",
      "C\n",
      "creature\n",
      "sorcery\n",
      "⌧\n",
      "soura\n",
      "enchanted creature that card onto the battlefield then creature that card onto the battlefield then creature that card onto the battlefield then creature that card onto the battlefield then creature that card onto the battlefield then creature that card onto the ba\n",
      "then creature of the battlefield target and that card onto the battlefield then creature target creature then creature libring creature gain 1 life target land onto the battlefield then creature the battlefield then your until end of turn.Ⓔ\n",
      "\n",
      "balkerre\n",
      "③Ⓖ\n",
      "R\n",
      "sorcery\n",
      "⌧\n",
      "creature target and onto the battlef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 101/5869 [1:39:00<94:13:49, 58.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wald opns 3 linagra creature of library that cards of target and life sacrifice tapped card onto your only and tappod, sacrifice a creature that card into gains an mise\n",
      "flying walked the battlefield untile target creature target spell/damasa, of to then card onto the beginning of turn.Ⓔ\n",
      "\n",
      "binus\n",
      "①\n",
      "C\n",
      "sor\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 115/5869 [1:53:08<94:20:51, 59.03s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-13cd8488fbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# fit to card batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# reset state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# just train, fix epochs later\n",
    "\n",
    "# save card predictions\n",
    "predictions = []\n",
    "\n",
    "for epoch_idx in range(START_EPOCH, NUM_EPOCHS):\n",
    "    # epochs are \"meaningless\" here, roughly batch size = 1 card so...\n",
    "    for batch in tqdm(range(int(len(cardtext)/CARDS_PER_BATCH))):\n",
    "        \n",
    "        # get batch\n",
    "        x_batch, y_batch = next(getbatch)\n",
    "        \n",
    "        # fit to card batch\n",
    "        r = model.fit(x_batch, y_batch, epochs=1, batch_size=1, shuffle=False, verbose=0)\n",
    "\n",
    "        # reset state\n",
    "        model.reset_states()\n",
    "        \n",
    "        # if batch % OUT_INCREMENT == 0 and batch > 0:\n",
    "\n",
    "        if batch % OUT_INCREMENT == 0 and batch > 0:\n",
    "            model.save_weights('model/v2B-modelweights-epoch{}-cards{}.h5'.format(epoch_idx+1, CARDS_PER_BATCH*(batch)))\n",
    "            print(\"EPOCH:\", epoch_idx+1, \"card #:\", batch, \"of\", len(cardtext), r)\n",
    "            predict(startchars='random', temperature='random')\n",
    "            predict(startchars='random', temperature='random')\n",
    "            predict(startchars='random', temperature='random')\n",
    "            predictions.append(\"EPOCH \"+str(epoch_idx+1)+\"cards:\"+str((batch)*CARDS_PER_BATCH)+\": \"+str(predict(startchars='random', temperature='random')))\n",
    "            print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # todo: just save to json one time\n",
    "# model.save('model/100test_model.h5')\n",
    "# print(\"saved model to disk\\n\")\n",
    "# model.save_weights('model/100test_model_weights.h5')\n",
    "# print(\"saved model weights to disk\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model.load_weights('model/100-modelweights-epoch71-batch99.h5')\n",
    "# START_EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(startchars='random', temperature='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
