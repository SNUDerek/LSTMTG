{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "cardtext = [list(x) for x in list(np.load('data/card_texts.npy'))]\n",
    "c2i = np.load('data/c2i.npy').item()\n",
    "i2c = np.load('data/i2c.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test - randomize!\n",
    "np.random.seed = 1337\n",
    "indices = list(np.random.permutation(len(cardtext)))\n",
    "cardtext = [cardtext[i] for i in indices]\n",
    "cardtext = cardtext[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "DROP_RATE = 0.25 # dropout\n",
    "EMBEDDING_SIZE = 256 # embedding size\n",
    "HIDDEN_SIZE = 256 # lstm feature vector\n",
    "HIDDEN_LAYERS = 2 # number of layers\n",
    "START_EPOCH = 0\n",
    "VOCAB_SIZE = len(c2i.keys()) # number of characters\n",
    "\n",
    "WINDOW_SIZE = 5 # context length\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "OUT_INCREMENT = 10 # printout after n EPOCHS - and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch generator\n",
    "def cardGenerator(cardtext, windowsize, strt='Ⓢ', pad='⎕', c2i=c2i):\n",
    "    \n",
    "    i = 0\n",
    "    indices = list(np.random.permutation(len(cardtext)))\n",
    "    idx = indices[i]\n",
    "    \n",
    "    # for each card...\n",
    "    # todo: shuffle this??\n",
    "    while True:\n",
    "\n",
    "        # new card, get index\n",
    "        thiscard = []\n",
    "        \n",
    "        # start-pad the window\n",
    "        for j in range(windowsize):    \n",
    "            thiscard.append(strt)\n",
    "\n",
    "        # add the cardtext\n",
    "        thiscard += cardtext[idx]\n",
    "        \n",
    "        # int-index\n",
    "        thiscard = [c2i[c] for c in thiscard]\n",
    "        \n",
    "        # create matrix\n",
    "        x = []\n",
    "        y = []\n",
    "        for k in range(len(thiscard)-windowsize):\n",
    "            x.append(thiscard[k:(k+windowsize)])\n",
    "            y.append(thiscard[k+windowsize])\n",
    "        \n",
    "        # reshape for sparse_categorical_crossentropy\n",
    "        y = np.array(y)\n",
    "        y = y[:, np.newaxis]\n",
    "        \n",
    "        yield(np.asarray(x), y)\n",
    "        \n",
    "        if i + 1 >= len(cardtext):\n",
    "            indices = np.random.permutation(len(cardtext))\n",
    "            i = 0\n",
    "            idx = indices[i]\n",
    "        else:\n",
    "            i += 1\n",
    "            idx = indices[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getbatch = cardGenerator(cardtext, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBEDDING_SIZE, \n",
    "                    batch_input_shape=(1, WINDOW_SIZE, )))\n",
    "model.add(Dropout(DROP_RATE))\n",
    "for _ in range(HIDDEN_LAYERS-1):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(HIDDEN_SIZE, stateful=True))\n",
    "model.add(Dense(VOCAB_SIZE, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 'Ⓢ'\n",
    "\n",
    "def predict(startchars='none', temperature=1.0, maxlen=300):\n",
    "    \n",
    "    seq_out = []\n",
    "    \n",
    "    if temperature=='random':\n",
    "        tmp = np.random.random()\n",
    "    else:\n",
    "        tmp = temperature\n",
    "    \n",
    "    # starting sequence\n",
    "    if startchars=='none':\n",
    "        seq_in = [c2i['Ⓢ'] for i in range(WINDOW_SIZE)]\n",
    "    \n",
    "    elif startchars=='random':\n",
    "        seq_in = [c2i['Ⓢ'] for i in range(WINDOW_SIZE-1)]\n",
    "        alpha = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k',\n",
    "                 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
    "                 'w', 'x', 'y', 'z']\n",
    "        alpha = [a for a in alpha if a in c2i.keys()]\n",
    "        rnd = np.random.randint(0, len(alpha))\n",
    "        seq_in += [c2i[alpha[rnd]]]\n",
    "        seq_out = [c2i[alpha[rnd]]]\n",
    "    \n",
    "    else:\n",
    "        s = list(startchars)\n",
    "        s = s[:WINDOW_SIZE]\n",
    "        seq_out =  [c2i[c] for c in s]\n",
    "        while len(s) < WINDOW_SIZE:\n",
    "            s.insert(0, 'Ⓢ')\n",
    "        seq_in = [c2i[c] for c in s]\n",
    "        \n",
    "    # softmax temperature\n",
    "    # scaling factor of logits = logits/temperature\n",
    "    # high temp = more confident = more diverse, more mistakes\n",
    "    # low temp: more conservative\n",
    "    # https://stackoverflow.com/questions/37246030/how-to-change-the-temperature-of-a-softmax-output-in-keras/37254117#37254117\n",
    "    def sample(a, temperature=tmp):\n",
    "        a = np.array(a)**(1/temperature)\n",
    "        p_sum = a.sum()\n",
    "        sample_temp = a/p_sum \n",
    "\n",
    "        # stupid fix for > 1 error\n",
    "        while sum(sample_temp) > 1:\n",
    "            sample_temp[0] -= 0.0001\n",
    "\n",
    "        return np.argmax(np.random.multinomial(1, sample_temp, 1))\n",
    "\n",
    "    for i in range(maxlen):\n",
    "\n",
    "        # predict next char\n",
    "        pred_out = model.predict(np.array(seq_in).reshape((1, WINDOW_SIZE)))\n",
    "        # get index of highest pred\n",
    "        idx = sample(pred_out[0])\n",
    "        # save index for decoding\n",
    "        seq_out.append(idx)\n",
    "        # add index to input sequence\n",
    "        seq_in.append(int(idx))\n",
    "        # remove earliest\n",
    "        seq_in.pop(0)\n",
    "\n",
    "    # decode final sequence\n",
    "    card_char = ''.join([i2c[int(i)] for i in seq_out])\n",
    "    card_text = card_char.split('|')\n",
    "    for f in card_text:\n",
    "        f = f.replace('Ⓝ', ''.join(card_text[0]))\n",
    "\n",
    "    for f in card_text:\n",
    "        print(f)\n",
    "        \n",
    "    return card_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model.load_weights('model/temp-modelweights-epoch26-batch957.h5')\n",
    "# START_EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epoch thru all cards\n",
    "for epoch_idx in range(START_EPOCH, NUM_EPOCHS):\n",
    "\n",
    "    # print(\"epoch\", epoch_idx, \"of\", NUM_EPOCHS)\n",
    "    \n",
    "    for batch in tqdm(range(len(cardtext))):\n",
    "        \n",
    "        # get batch (one card)\n",
    "        x_batch, y_batch = next(getbatch)\n",
    "        \n",
    "        # fit to card batch\n",
    "        r = model.fit(x_batch, y_batch, \n",
    "                      epochs=1, batch_size=1, shuffle=False,\n",
    "                      verbose=0)\n",
    "\n",
    "        # reset state\n",
    "        model.reset_states()\n",
    "        \n",
    "        # if batch % OUT_INCREMENT == 0 and batch > 0:\n",
    "\n",
    "    if epoch_idx % OUT_INCREMENT == 0 and epoch_idx > 0:\n",
    "        model.save_weights('model/100-modelweights-epoch{}-batch{}.h5'.format(epoch_idx+1, batch))\n",
    "        print(\"EPOCH:\", epoch_idx+1, \"card #:\", batch, \"of\", len(cardtext), r)\n",
    "        predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # todo: just save to json one time\n",
    "model.save('model/100test_model.h5')\n",
    "print(\"saved model to disk\\n\")\n",
    "model.save_weights('model/100test_model_weights.h5')\n",
    "print(\"saved model weights to disk\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model.load_weights('model/100-modelweights-epoch71-batch99.h5')\n",
    "# START_EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(startchars='random', temperature='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
